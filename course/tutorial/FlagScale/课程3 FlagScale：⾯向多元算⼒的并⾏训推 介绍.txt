课程名称：FlagScale：面向多元算力的并行训推

课程介绍：  
FlagScale 是由北京智源人工智能研究院推出的开源大模型训推一体化框架，专为多元算力环境设计，支持多芯片、多后端的分布式训练与高效推理。本课程围绕 FlagScale 的核心能力展开，系统讲解其在大模型生命周期中的关键作用，涵盖分布式训练优化、推理部署加速、异构混训、跨芯片自适应调优等前沿技术。

课程亮点包括：支持多芯片（如英伟达、华为、寒武纪、摩尔线程等）一键部署与调优；集成 vLLM、SGLang、llama.cpp 等多后端推理框架；提供自动并行策略搜索与显存预估，显著提升训练效率与推理性能；并通过 FlagRelease 实现模型跨平台自动发版与持续集成。

本课程适合深度学习系统开发者、AI 平台架构师、大模型训练与部署工程师，以及对多元算力适配和高效训推系统感兴趣的研究人员。通过学习，学员将掌握如何在复杂硬件环境中高效训练与部署大模型，提升系统性能与资源利用率，助力构建面向未来的 AI 基础设施。